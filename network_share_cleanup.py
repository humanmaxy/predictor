#!/usr/bin/env python3
"""
ç½‘ç»œå…±äº«ç›®å½•èŠå¤©æ¸…ç†æœåŠ¡
æ¨¡æ‹Ÿæ¯å¤©å‡Œæ™¨2ç‚¹æ¸…ç†æ—§æ•°æ®
"""

import os
import json
import time
import schedule
from datetime import datetime, timedelta
from pathlib import Path
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cleanup.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class NetworkShareCleaner:
    """ç½‘ç»œå…±äº«ç›®å½•æ¸…ç†å™¨"""
    def __init__(self, share_path: str):
        self.share_path = Path(share_path)
        self.public_dir = self.share_path / "public"
        self.private_dir = self.share_path / "private"
        self.users_dir = self.share_path / "users"
        self.logs_dir = self.share_path / "logs"
        
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        self.logs_dir.mkdir(parents=True, exist_ok=True)
    
    def cleanup_old_data(self, days_to_keep=1):
        """æ¸…ç†æ—§æ•°æ®"""
        logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥æ¸…ç†ä»»åŠ¡...")
        
        cutoff_time = datetime.now() - timedelta(days=days_to_keep)
        total_deleted = 0
        
        try:
            # æ¸…ç†ç¾¤èŠæ¶ˆæ¯
            public_deleted = self._cleanup_directory(self.public_dir, cutoff_time)
            total_deleted += public_deleted
            logger.info(f"æ¸…ç†ç¾¤èŠæ¶ˆæ¯: {public_deleted} ä¸ªæ–‡ä»¶")
            
            # æ¸…ç†ç§èŠæ¶ˆæ¯
            private_deleted = self._cleanup_private_messages(cutoff_time)
            total_deleted += private_deleted
            logger.info(f"æ¸…ç†ç§èŠæ¶ˆæ¯: {private_deleted} ä¸ªæ–‡ä»¶")
            
            # æ¸…ç†è¿‡æœŸå¿ƒè·³æ–‡ä»¶
            heartbeat_deleted = self._cleanup_heartbeat_files(cutoff_time)
            total_deleted += heartbeat_deleted
            logger.info(f"æ¸…ç†å¿ƒè·³æ–‡ä»¶: {heartbeat_deleted} ä¸ªæ–‡ä»¶")
            
            # è®°å½•æ¸…ç†ç»Ÿè®¡
            self._log_cleanup_stats(total_deleted, days_to_keep)
            
            logger.info(f"æ¸…ç†å®Œæˆï¼Œæ€»å…±åˆ é™¤ {total_deleted} ä¸ªæ–‡ä»¶")
            return total_deleted
            
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return 0
    
    def _cleanup_directory(self, directory: Path, cutoff_time: datetime):
        """æ¸…ç†æŒ‡å®šç›®å½•"""
        deleted_count = 0
        
        try:
            if not directory.exists():
                return 0
            
            for file_path in directory.glob("*.json"):
                file_mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                if file_mtime < cutoff_time:
                    file_path.unlink()
                    deleted_count += 1
                    logger.debug(f"åˆ é™¤æ–‡ä»¶: {file_path}")
                    
        except Exception as e:
            logger.error(f"æ¸…ç†ç›®å½•å¤±è´¥ {directory}: {e}")
        
        return deleted_count
    
    def _cleanup_private_messages(self, cutoff_time: datetime):
        """æ¸…ç†ç§èŠæ¶ˆæ¯"""
        deleted_count = 0
        
        try:
            if not self.private_dir.exists():
                return 0
            
            for private_chat_dir in self.private_dir.iterdir():
                if private_chat_dir.is_dir():
                    # æ¸…ç†ç§èŠç›®å½•ä¸­çš„æ¶ˆæ¯æ–‡ä»¶
                    dir_deleted = self._cleanup_directory(private_chat_dir, cutoff_time)
                    deleted_count += dir_deleted
                    
                    # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
                    if not any(private_chat_dir.iterdir()):
                        private_chat_dir.rmdir()
                        logger.debug(f"åˆ é™¤ç©ºç›®å½•: {private_chat_dir}")
                        
        except Exception as e:
            logger.error(f"æ¸…ç†ç§èŠæ¶ˆæ¯å¤±è´¥: {e}")
        
        return deleted_count
    
    def _cleanup_heartbeat_files(self, cutoff_time: datetime):
        """æ¸…ç†å¿ƒè·³æ–‡ä»¶"""
        deleted_count = 0
        
        try:
            if not self.users_dir.exists():
                return 0
            
            for heartbeat_file in self.users_dir.glob("*_heartbeat.json"):
                file_mtime = datetime.fromtimestamp(heartbeat_file.stat().st_mtime)
                if file_mtime < cutoff_time:
                    heartbeat_file.unlink()
                    deleted_count += 1
                    logger.debug(f"åˆ é™¤å¿ƒè·³æ–‡ä»¶: {heartbeat_file}")
                    
        except Exception as e:
            logger.error(f"æ¸…ç†å¿ƒè·³æ–‡ä»¶å¤±è´¥: {e}")
        
        return deleted_count
    
    def _log_cleanup_stats(self, deleted_count: int, days_kept: int):
        """è®°å½•æ¸…ç†ç»Ÿè®¡"""
        stats_file = self.logs_dir / "cleanup_stats.json"
        
        stats_data = {
            "cleanup_time": datetime.now().isoformat(),
            "deleted_files": deleted_count,
            "days_kept": days_kept,
            "share_path": str(self.share_path)
        }
        
        try:
            # è¯»å–ç°æœ‰ç»Ÿè®¡
            all_stats = []
            if stats_file.exists():
                with open(stats_file, 'r', encoding='utf-8') as f:
                    all_stats = json.load(f)
            
            # æ·»åŠ æ–°ç»Ÿè®¡
            all_stats.append(stats_data)
            
            # åªä¿ç•™æœ€è¿‘30å¤©çš„ç»Ÿè®¡
            if len(all_stats) > 30:
                all_stats = all_stats[-30:]
            
            # ä¿å­˜ç»Ÿè®¡
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(all_stats, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"è®°å½•æ¸…ç†ç»Ÿè®¡å¤±è´¥: {e}")
    
    def get_storage_info(self):
        """è·å–å­˜å‚¨ä¿¡æ¯"""
        try:
            public_count = len(list(self.public_dir.glob("*.json"))) if self.public_dir.exists() else 0
            private_count = 0
            
            if self.private_dir.exists():
                for private_chat_dir in self.private_dir.iterdir():
                    if private_chat_dir.is_dir():
                        private_count += len(list(private_chat_dir.glob("*.json")))
            
            users_count = len(list(self.users_dir.glob("*_heartbeat.json"))) if self.users_dir.exists() else 0
            
            return {
                "public_messages": public_count,
                "private_messages": private_count,
                "active_users": users_count,
                "total_files": public_count + private_count + users_count
            }
            
        except Exception as e:
            logger.error(f"è·å–å­˜å‚¨ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)}

def run_cleanup_service(share_path: str):
    """è¿è¡Œæ¸…ç†æœåŠ¡"""
    cleaner = NetworkShareCleaner(share_path)
    
    # è®¾ç½®æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†
    schedule.every().day.at("02:00").do(cleaner.cleanup_old_data)
    
    logger.info("æ¸…ç†æœåŠ¡å·²å¯åŠ¨ï¼Œæ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†ä»»åŠ¡")
    logger.info(f"ç›‘æ§ç›®å½•: {share_path}")
    
    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        logger.info("æ¸…ç†æœåŠ¡å·²åœæ­¢")

def manual_cleanup(share_path: str, days_to_keep=1):
    """æ‰‹åŠ¨æ‰§è¡Œæ¸…ç†"""
    cleaner = NetworkShareCleaner(share_path)
    
    print(f"ğŸ§¹ æ‰‹åŠ¨æ¸…ç†ç½‘ç»œå…±äº«ç›®å½•: {share_path}")
    print(f"ğŸ“… ä¿ç•™å¤©æ•°: {days_to_keep} å¤©")
    
    # æ˜¾ç¤ºæ¸…ç†å‰çš„ç»Ÿè®¡
    before_stats = cleaner.get_storage_info()
    print(f"ğŸ“Š æ¸…ç†å‰ç»Ÿè®¡: {before_stats}")
    
    # æ‰§è¡Œæ¸…ç†
    deleted_count = cleaner.cleanup_old_data(days_to_keep)
    
    # æ˜¾ç¤ºæ¸…ç†åçš„ç»Ÿè®¡
    after_stats = cleaner.get_storage_info()
    print(f"ğŸ“Š æ¸…ç†åç»Ÿè®¡: {after_stats}")
    print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶")

def show_storage_stats(share_path: str):
    """æ˜¾ç¤ºå­˜å‚¨ç»Ÿè®¡"""
    cleaner = NetworkShareCleaner(share_path)
    stats = cleaner.get_storage_info()
    
    print("ğŸ“Š ç½‘ç»œå…±äº«èŠå¤©å®¤å­˜å‚¨ç»Ÿè®¡")
    print("=" * 40)
    print(f"ğŸ“ å…±äº«è·¯å¾„: {share_path}")
    print(f"ğŸ’¬ ç¾¤èŠæ¶ˆæ¯: {stats.get('public_messages', 0)} æ¡")
    print(f"ğŸ”’ ç§èŠæ¶ˆæ¯: {stats.get('private_messages', 0)} æ¡")
    print(f"ğŸ‘¥ æ´»è·ƒç”¨æˆ·: {stats.get('active_users', 0)} äºº")
    print(f"ğŸ“„ æ€»æ–‡ä»¶æ•°: {stats.get('total_files', 0)} ä¸ª")

def main():
    """ä¸»å‡½æ•°"""
    share_path = r"\\catl-tfile\Temp1dayæ¯å¤©å‡Œæ™¨ä¸¤ç‚¹æ¸…ç†æ•°æ®01\imdmmm"
    
    print("ğŸ§¹ ç½‘ç»œå…±äº«èŠå¤©å®¤æ¸…ç†å·¥å…·")
    print("=" * 50)
    
    print(f"ğŸ“ ç›®æ ‡è·¯å¾„: {share_path}")
    print()
    
    print("é€‰æ‹©æ“ä½œ:")
    print("1. æŸ¥çœ‹å­˜å‚¨ç»Ÿè®¡")
    print("2. æ‰‹åŠ¨æ¸…ç†ï¼ˆä¿ç•™1å¤©ï¼‰")
    print("3. æ‰‹åŠ¨æ¸…ç†ï¼ˆä¿ç•™3å¤©ï¼‰")
    print("4. å¯åŠ¨æ¸…ç†æœåŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹è‡ªåŠ¨æ¸…ç†ï¼‰")
    print("5. æµ‹è¯•ç›®å½•è®¿é—®")
    print("6. é€€å‡º")
    
    choice = input("\nè¯·é€‰æ‹© (1-6): ").strip()
    
    if choice == "1":
        show_storage_stats(share_path)
    
    elif choice == "2":
        manual_cleanup(share_path, days_to_keep=1)
    
    elif choice == "3":
        manual_cleanup(share_path, days_to_keep=3)
    
    elif choice == "4":
        print("ğŸ• å¯åŠ¨æ¸…ç†æœåŠ¡...")
        run_cleanup_service(share_path)
    
    elif choice == "5":
        try:
            cleaner = NetworkShareCleaner(share_path)
            if cleaner.check_access():
                print("âœ… ç›®å½•è®¿é—®æµ‹è¯•æˆåŠŸ")
            else:
                print("âŒ ç›®å½•è®¿é—®æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    elif choice == "6":
        print("ğŸ‘‹ é€€å‡º")
    
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦éœ€è¦å®‰è£…scheduleåº“
    try:
        import schedule
    except ImportError:
        print("âŒ ç¼ºå°‘scheduleåº“ï¼Œè¯·å®‰è£…: pip install schedule")
        print("æˆ–è€…ä½¿ç”¨æ‰‹åŠ¨æ¸…ç†åŠŸèƒ½")
        
    main()