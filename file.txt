Topic 1：基于多模态融合与特征迁移的工业缺陷检测（交付期限月1自然年）
1. 项目需求详细描述
当前高端制造业特别是（如新能源电池、半导体芯片）的缺陷检测面临诸多挑战：缺陷类型多样（划痕、凹陷、杂质、漏焊等）、背景复杂、传统单一视觉模态（如2D RGB相机）受光照、材质、表面反光影响大，导致切拉换型或工艺改变后漏检（False Negative）和过杀（False Positive）率增高。
本项目旨在研发一套基于多模态信息融合与特征迁移的下一代智能视觉检测系统。核心思想是协同利用2D RGB图像、3D点云/深度数据、以及X-ray成像、红外热成像等多种传感器信息，通过先进的融合算法，提取互补性特征，克服单一模态的感知局限，实现对复杂缺陷的高精度、高鲁棒性、高效率识别与分类。
具体需求包括：
1.多模态数据协同采集与处理：设计一套可集成RGB相机、3D结构光/激光轮廓仪、红外热像仪的综合采集系统，并解决多传感器在时间与空间上的同步与标定问题。
2.跨模态特征融合与对齐：研究有效的融合架构（如基于注意力机制、图神经网络或借鉴CLIP思想的跨模态对齐网络），将不同模态的特征在统一空间中进行对齐和深度融合，而非简单的数据堆叠或决策层融合。
3. 多模型协同检测与智能路由机制：由于不同数据源的缺陷或检测特性不同，应用的如YOLO、FastIns、SAM2等模型在检测速度、场景类别应用范围不同。
。需构建一个模型仓库，集成诸如YOLO系列（追求高速度的通用缺陷定位）、FastInst（高精度的实例分割）、SAM2（强大的零样本分割能力用于新缺陷）、以及专用分类网络等。开发一套智能模型路由策略。该策略能根据实时分析的多模态数据特征（如图像纹理复杂度、深度信息丰富度、有无热异常）和检测任务上下文（如当前产线节拍要求、缺陷类型优先级），动态选择最合适的一个或一组模型进行协同推理和阈值参数优化。
目标：实现速度与精度的最优平衡，避免为追求极高精度而在简单场景下使用大模型造成的算力浪费，确保系统整体效率。
4.小样本与弱监督学习能力：针对工业场景中难以获取大量缺陷样本（尤其是罕见缺陷）的痛点，研究基于自监督学习或特征迁移的方法，利用正常样本或少量标注样本进行模型训练，提升模型泛化能力。
5.工程化与部署：研发的算法模型需考虑最终在边缘计算设备或工控机上的部署，平衡计算复杂度与检测精度，满足产线节拍要求。
2. 期望达成的技术指标 
技术指标	目标值	备注
综合检测率 (Recall)
理论0漏杀
核心指标，极大降低漏检风险
过杀率 (False Positive Rate)
≤ 0.5%
核心指标，极大减少误判导致的良品浪费
检测节拍
≤ XX ms/件
根据具体产线速度设定，需满足实时性
多模态数据同步误差
＜ 100ms
保证不同传感器数据在时间上对齐
模型大小
＜ 100MB
便于部署和更新（可选，依赖硬件）
支持缺陷类型
≥  种
覆盖目标产线所有关键缺陷类型
人工复检比率
降低 ≥ 80%
大幅减少人工复检工位

Topic 2：面向智能制造的三维建模与数字孪生与机器人协同应用（交付期限月2-3自然年）
1. 项目需求详细描述
在电池制造领域（如电池盒、电芯、精密壳体、封装件），传统的基于二维图像的尺寸检测和来料检验需要一次性拍摄几十上百张图像，通过不同的检测策略对检测项进行检测，这种检测方式在结合不同相机、设备、数据源进行协同时完全依赖于人工代码配置，存在局限性，无法协同多相机甚至多传感器的测量高度、平面度、装配间隙、孔位深度等三维维度上的偏差。这些微米级的形变和尺寸异常是导致产品不良和安全隐患的关键因素。同时，工厂数字化升级中，虚拟调试、产线仿真、机器人离线编程等都依赖于高保真的三维环境模型。
本项目旨在构建一个协同的工业三维智能建模与应用系统，其核心不再是单纯地“重建场景”，而是为质量控制和自动化决策提供精准的三维数据基石，并为未来机器人介入的真正无人化产线探索数据及环境基础。
具体需求包括：
1.面向质量检测的自动化三维重建：研发基于多目视觉、结构光等技术的在线式三维扫描站，集成于关键工位（如来料检验、装配完成后），自动、快速地生成待检工件的高精度三维点云与网格模型，替代传统三坐标测量（CMM）等离线、抽检方式。
2.AI驱动的实时点云处理与分析：对生成的三维模型进行实时语义分割，精确分离背景、工装、工件本身；并基于AI算法将其与标准CAD数字模型进行自动比对，实现全尺寸测量（GD&T）和形变分析。
3. 光源等信源校正和简单场景的设备自主纠偏：
多传感器协同与自主标定校正：
三维扫描站本身是一个复杂的光学测量系统，其内部多个相机、投影仪的光学参数会随时间发生微漂移。
系统需集成自动化自标定功能。能够定期（如每班次开始时）或按需驱动扫描站对内置的高精度标准标定板进行扫描，自动计算传感器参数的变化并进行软件校正，无需人工干预即可保持系统长期测量精度。
对于因振动、温差导致的机械结构轻微形变（简单场景的自主纠偏），系统应能通过分析点云数据特征，检测到这种变化，并尝试在算法层面进行补偿，或果断报警请求维护，防止产生批量误测。
3.轻量化与可视化：研究压缩算法，在保证关键特征精度的前提下，对模型进行轻量化处理，实现在网页端、移动端或AR/VR设备上的流畅渲染与交互，用于远程评审、作业指导与培训。
4.与数字孪生平台集成：将三维检测结果（尺寸偏差、缺陷点云）实时映射到工厂的数字孪生体中，不仅实现可视化，更关键的是驱动质量数据分析、生产流程优化和设备预维护，形成“感知-分析-决策”的闭环。
5.与数字孪生平台及自动化设备协同应用：
将三维检测结果实时映射到工厂的数字孪生体中，驱动质量数据分析、生产流程优化和设备预维护。项目的探索方向，三维系统生成的精确点云模型，
可用于：
机器人视觉引导：为装配机器人提供高精度的工件6D位姿，实现柔性装配。
自适应加工：基于三维扫描的实际工件尺寸，实时生成加工路径，如补偿来料或上道工序的误差。
闭环反馈：机器人执行操作后，可再次扫描，由系统验证操作结果（如装配间隙是否合格），形成“感知-决策-执行-验证”的全自动闭环。

2. 期望达成的技术指标
技术指标	目标值	备注
三维尺寸检测精度
≤ ± 0.05 mm
关键指标，满足精密制造测量需求
三维检测节拍
≤ 5-10 秒/件
远快于传统C测量，可实现全检
基于三维模型的过杀率降低
≥ 30%
通过精确的3D测量，避免2D误判
基于三维模型的漏检率降低
≥ 40%
检出2D无法发现的形变、装配不良等
产线良品率提升
提升 0.5% - 1.5%
因早期发现并剔除不良品，整体良率提升
替代人工检测工位
≥ 2 个工位
直接替代原有的人工目检或离线测量工位
数字孪生模型同步延迟
＜ 3 秒
从物理实体扫描到孪生体更新显示的延迟

